Automatic Prompt Engineer (APE) is a system proposed by Zhou et al. (2022) to automatically create and choose instructions (or prompts) for tasks. The process of generating these instructions is treated like a black-box optimization problem, where a large language model (LLM) generates multiple possible instructions and then searches for the best one.

Here’s how APE works:

1. Instruction Generation: A large language model is given some examples of a task’s output and asked to come up with instruction candidates. These instructions will guide how the model should handle similar tasks in the future.
  
2. Instruction Selection: These instruction candidates are then tested using a target model to see how well they perform. The instruction that produces the best results (based on evaluation scores) is chosen.

APE outperforms human-crafted prompts, like the well-known "Let's think step by step" prompt (Kojima et al., 2022). Instead, it suggests a better one: "Let's work this out in a step-by-step way to be sure we have the right answer." This improvement leads to better reasoning and results on benchmarks like MultiArith and GSM8K.

Related Works

Although this guide doesn't cover the broader topic of prompt optimization, here are some other notable works in this area:

- Prompt-OIRL: Uses offline inverse reinforcement learning to generate task-specific prompts.
- OPRO: Suggests that LLMs can optimize prompts, such as using the phrase "Take a deep breath" to improve performance on math problems.
- AutoPrompt: Automatically creates prompts for various tasks using a method based on gradient-guided search.
- Prefix Tuning: A simpler alternative to fine-tuning that adds a trainable prefix to improve natural language generation (NLG) tasks.
- Prompt Tuning: Focuses on learning soft prompts through backpropagation for better task performance. 

In essence, APE and these other methods aim to make prompting more efficient and effective by automating the process.