What is ReAct Prompting?

In 2022, researchers Yao and colleagues introduced a new way to use large language models (LLMs) called **ReAct**. This method allows these models to combine reasoning and specific actions, helping them solve problems more effectively.

Why Use ReAct? 
ReAct helps LLMs think through their actions, keep track of what they’re doing, and adjust their plans if needed. It also enables them to gather information from outside sources, like databases or the internet, which makes their responses more accurate.

Results:  
The ReAct approach has shown better performance on various language and decision-making tasks compared to older methods. It also helps humans understand the model's reasoning better, which builds trust in the model's answers. The best results come when ReAct is used alongside a technique called chain-of-thought (CoT), which helps the model combine its knowledge with information it finds during the reasoning process.

How Does ReAct Work?

ReAct is built on the idea that humans learn by acting and reasoning together. When we face a problem, we think through it while also taking actions to gather more information.

Traditional chain-of-thought prompting (CoT) helps LLMs reason through tasks involving basic math and common sense. However, it struggles with accessing up-to-date information, which can lead to incorrect answers or "hallucinations" (i.e., false facts).

The ReAct Method:
ReAct encourages LLMs to express their thoughts and actions for a specific task. This approach allows them to adjust their plans dynamically and access outside information (like Wikipedia) to enhance their reasoning process.

Example of ReAct in Action:
Suppose we want to ask the following question: 

"What other devices can control the program originally designed to work with the Apple Remote?"

The model will process this question by thinking through several steps, which are:

1. Thought: I need to search for information about the Apple Remote and its compatible devices.
2. Action: Search for "Apple Remote compatible devices."
3. Observation: Retrieve relevant information from a search engine.
4. Thought: Now that I have the information, I’ll determine what other devices might be compatible.

Understanding ReAct Prompting Steps

Here’s a breakdown of how ReAct prompting works using a question from a dataset:

Example Question:
"What is the elevation range for the eastern sector of the Colorado orogeny?"

1. Thought 1: I need to look up the Colorado orogeny and find out where the eastern sector is located.
2. Action 1: Search for "Colorado orogeny."
3. Observation 1: Learn that the Colorado orogeny was a mountain-building event.
4. Thought 2: I didn’t find specifics about the eastern sector; I need to search for that.
5. Action 2: Search for "eastern sector of the Colorado orogeny."
6. Observation 2: Find out that the eastern sector is called the Central Plains orogeny.
7. Thought 3: Now, I should find the elevation of the High Plains, where the eastern sector extends.
8. Action 3: Search for "High Plains elevation."
9. Observation 3: Discover that the High Plains rise from 1,800 to 7,000 feet.

Finally, the model concludes that the answer is "1,800 to 7,000 feet."

Results on Knowledge Tasks

The researchers tested ReAct on tasks requiring knowledge, like answering questions and verifying facts, using a large model called PaLM-540B. 

Findings:
- ReAct generally outperformed a method that only involved acting (called Act) and often did better than the chain-of-thought method (CoT) in some tasks. 
- However, CoT did better in other areas, like HotpotQA, highlighting the strengths and weaknesses of each approach.

Results on Decision Making Tasks

ReAct was also tested in decision-making environments like ALFWorld (a text-based game) and WebShop (an online shopping environment). Here, ReAct again outperformed the acting-only method. 

Key Takeaway:  
While ReAct shows promising results, it still doesn’t match expert human performance in these complex tasks.

Using ReAct with LangChain

Here’s a simple example of how you can use ReAct in a programming context with LangChain:

1. Install Required Libraries:
   ```bash
   !pip install --upgrade openai langchain python-dotenv google-search-results
   ```

2. Import the Libraries:
   ```python
   import openai
   import os
   from langchain.llms import OpenAI
   from langchain.agents import load_tools, initialize_agent
   from dotenv import load_dotenv
   load_dotenv()
   ```

3. Set Up API Keys:
   ```python
   os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
   os.environ["SERPER_API_KEY"] = os.getenv("SERPER_API_KEY")
   ```

4. Configure LLM and Agent:
   ```python
   llm = OpenAI(model_name="text-davinci-003", temperature=0)
   tools = load_tools(["google-serper", "llm-math"], llm=llm)
   agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)
   ```

5. Run the Agent:
   ```python
   agent.run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")
   ```

The output would give you the boyfriend's name and the calculated value based on his age.

By experimenting with different tools and tasks, you can explore the full potential of the ReAct framework.

For more details, you can check out the notebook https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/react.ipynb