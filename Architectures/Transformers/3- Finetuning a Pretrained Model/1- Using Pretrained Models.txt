Using Pretrained Models

The Model Hub makes it easy to choose the right model, so you can use it in any library with just a few lines of code. Let’s see how to use one of these models and also contribute back to the community.

Suppose we're looking for a model that understands French and can perform "mask filling."

>> Selecting the Camembert Model

  We choose the `camembert-base` model to try out. The name `camembert-base` is all we need to start using it! As we've seen before, we can load it using the `pipeline()` function:

python code

'''
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
'''

When you run this, the model predicts possible words to fill in the blank (`<mask>`):

python code

'''
[
  {'sequence': 'Le camembert est délicieux :)', 'score': 0.49, 'token': 7200, 'token_str': 'délicieux'},
  {'sequence': 'Le camembert est excellent :)', 'score': 0.10, 'token': 2183, 'token_str': 'excellent'},
  {'sequence': 'Le camembert est succulent :)', 'score': 0.03, 'token': 26202, 'token_str': 'succulent'},
  {'sequence': 'Le camembert est meilleur :)', 'score': 0.03, 'token': 528, 'token_str': 'meilleur'},
  {'sequence': 'Le camembert est parfait :)', 'score': 0.03, 'token': 1654, 'token_str': 'parfait'}
]
'''

As you can see, loading a model is straightforward. However, you need to ensure that the model you choose is suitable for the task. For example, here we're using `camembert-base` for "fill-mask," which works perfectly. But if we used it for text classification, it wouldn’t work because the model isn’t designed for that!

>> Choosing the Right Model

   To make sure you select the right model, you can use the task selector on the Hugging Face Hub. 

   You can also load the model directly using its specific architecture:

python code

'''
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
'''

However, it’s better to use the `Auto*` classes instead, as they are flexible and can work with any model architecture:

python code

'''
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
'''

This way, switching models is easy!